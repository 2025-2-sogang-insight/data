import json
import os
import re
from pathlib import Path

# ==========================================
# 0. ì„¤ì •: ì‚­ì œí•  ëª©ì°¨ ì œëª© (ë¸”ë™ë¦¬ìŠ¤íŠ¸)
# ==========================================
EXCLUDED_HEADINGS = {
    "ê°œìš”", "ë°°ê²½", "ì±”í”¼ì–¸ ê´€ê³„", "ëŒ€ì‚¬", "ì˜ì›ì„", 
    "ì‹œë¦¬ì¦ˆ 1", "ì‹œë¦¬ì¦ˆ 2", "ì—­ì‚¬", "ì´ì „ ì‹œì¦Œ(2012 ~ 2024)", 
    "ì „ëµì  íŒ€ ì „íˆ¬", "ë ˆì „ë“œ ì˜¤ë¸Œ ë£¬í…Œë¼", "ìš°ë¥´í”„ ëª¨ë“œ", 
    "ì™€ì¼ë“œ ë¦¬í”„íŠ¸", "ìŠ¤í‚¨", "ê¸°íƒ€", "êµ¬ ì„¤ì •"
}

# ==========================================
# 1. í…ìŠ¤íŠ¸ ì •ì œ í•¨ìˆ˜ (Utils)
# ==========================================
def clean_text_content(text):
    if not text: return ""

    # 1. íƒœê·¸ ì œê±°
    text = re.sub(r'\[.*?\]', '', text)

    # 2. ëª©ì°¨ ë²ˆí˜¸ ì œê±°
    text = re.sub(r'(^|\s)\d+(\.\d+)+\.?\s+', ' ', text)
    text = re.sub(r'(^|\s)\d+\.\s+', ' ', text)

    # 3. ê³µë°± ì •ê·œí™”
    text = re.sub(r'\s+', ' ', text).strip()

    # 4. ì°¸ì¡°/ì°¸ê³  ê´€ë ¨ ë¬¸ì¥ ì œê±°
    text = _remove_reference_sentences(text)

    # 5. ì¤‘ë³µ ë¬¸ì¥ ì œê±°
    text = _remove_duplicate_sentences(text)

    # 6. ë§ê¼¬ë¦¬ ë°˜ë³µ ì œê±°
    text = _remove_tail_repetitions(text)

    return text

def _remove_reference_sentences(text):
    """íŠ¹ì • í‚¤ì›Œë“œ(ì°¸ì¡°, ì°¸ê³ í•˜ì‹­ì‹œì˜¤ ë“±)ê°€ í¬í•¨ëœ 'ë¬¸ì¥'ë§Œ ì œê±°"""
    sentences = re.split(r'(?<=[.?!])\s+', text)
    valid_sentences = []

    for s in sentences:
        s_stripped = s.strip()
        if not s_stripped: continue

        if "ì°¸ì¡°" in s_stripped: continue
        if "ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì‹­ì‹œì˜¤" in s_stripped: continue
        if re.search(r'ìì„¸í•œ ë‚´ìš©ì€.*?ì°¸ê³ í•˜ì‹­ì‹œì˜¤', s_stripped): continue

        valid_sentences.append(s_stripped)

    return ' '.join(valid_sentences)

def _remove_duplicate_sentences(text):
    sentences = re.split(r'(?<=[.?!])\s+', text)
    unique_sentences = []
    seen = set()

    for sentence in sentences:
        s = sentence.strip()
        if not s or (len(s) < 5 and s[-1] not in ['.', '?', '!']): 
            continue
        
        if s not in seen:
            unique_sentences.append(s)
            seen.add(s)
            
    return ' '.join(unique_sentences)

def _remove_tail_repetitions(text):
    while True:
        match = re.search(r'(\s\S.{1,20})(?:\1)+$', text)
        if match:
            text = text[:match.start()].strip()
        else:
            break
    return text

def clean_heading(heading):
    if not heading: return ""
    cleaned = re.sub(r'\[.*?\]', '', heading)
    cleaned = re.sub(r'^\d+(\.\d+)*\.?\s*', '', cleaned)
    return cleaned.strip()

# ==========================================
# 2. íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜ (í•µì‹¬ ë¡œì§)
# ==========================================
def process_json_file(input_path, output_path):
    try:
        file_name = Path(input_path).name
        is_general_file = file_name.startswith("ë¦¬ê·¸-ì˜¤ë¸Œ-ë ˆì „ë“œ")

        with open(input_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        new_data = data.copy()
        processed_sections = []
        blocked_prefixes = set()

        if "sections" in data:
            for section in data["sections"]:
                original_heading = section.get("heading", "")
                original_text = section.get("text", "")

                # ë²ˆí˜¸ ì¶”ì¶œ
                match_num = re.match(r'^(\d+(\.\d+)*\.?)', original_heading.strip())
                current_number = match_num.group(1) if match_num else None

                # ê³„ì¸µ ì‚­ì œ ê²€ì‚¬
                if current_number:
                    is_child_of_blocked = False
                    for prefix in blocked_prefixes:
                        if current_number.startswith(prefix):
                            is_child_of_blocked = True
                            break
                    if is_child_of_blocked: continue

                # ì œëª© ê¸°ë°˜ ì°¨ë‹¨
                if "ì‚¬ê±´" in original_heading and "ì‚¬ê³ " in original_heading:
                    if current_number: blocked_prefixes.add(current_number)
                    continue
                if "ë‹¤ë¥¸ ëª¨ë“œ/ê²Œì„ì—ì„œì˜ í”Œë ˆì´" in original_heading:
                    if current_number: blocked_prefixes.add(current_number)
                    continue

                # ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì œëª© ì°¨ë‹¨ (ì¼ë°˜ íŒŒì¼ ì œì™¸)
                cleaned_heading = clean_heading(original_heading)
                if not is_general_file and cleaned_heading in EXCLUDED_HEADINGS:
                    if current_number: blocked_prefixes.add(current_number)
                    continue

                # =======================================================
                # 3. ì •ì œ ìˆ˜í–‰ ë° ì œëª© ì¤‘ë³µ ì œê±°
                # =======================================================
                cleaned_text = clean_text_content(original_text)

                if cleaned_heading:
                    # (1) [ê¸°ì¡´] í…ìŠ¤íŠ¸ê°€ ì œëª©ìœ¼ë¡œ ì‹œì‘í•˜ë©´ ì œê±°
                    # ì˜ˆ: Heading="ê°œìš”", Text="ê°œìš” ë‚´ìš©ì€..." -> "ë‚´ìš©ì€..."
                    pattern_start = r'^(' + re.escape(cleaned_heading) + r'\s*)+'
                    cleaned_text = re.sub(pattern_start, '', cleaned_text).strip()

                    # (2) [NEW] ì œëª©ì´ í…ìŠ¤íŠ¸ë³´ë‹¤ ê¸¸ê³ , ì œëª©ì´ í…ìŠ¤íŠ¸ë¡œ ì‹œì‘í•˜ë©´ ì œê±°
                    # ì˜ˆ: Heading="ë‚´ì…” ë‚¨ì‘ (Baron)", Text="ë‚´ì…” ë‚¨ì‘" -> "" (ì‚­ì œ)
                    if cleaned_text and len(cleaned_text) < len(cleaned_heading):
                         if cleaned_heading.startswith(cleaned_text):
                             cleaned_text = ""

                    # (3) [ê¸°ì¡´] ì œëª©ì´ í…ìŠ¤íŠ¸ ëì—ì„œ ë°˜ë³µë˜ë©´ ì œê±°
                    pattern_end = r'(' + re.escape(cleaned_heading) + r'\s*)+$'
                    cleaned_text = re.sub(pattern_end, '', cleaned_text).strip()
                    
                    cleaned_text = cleaned_text.lstrip('.,- ').strip()

                if cleaned_text:
                    processed_sections.append({
                        "heading": cleaned_heading,
                        "text": cleaned_text
                    })
        
        new_data["sections"] = processed_sections

        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(new_data, f, indent=2, ensure_ascii=False)
            
        print(f"âœ… ìƒì„± ì™„ë£Œ: {file_name}")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ ({input_path}): {e}")

def process_directory(input_dir, output_dir):
    input_dir_path = Path(input_dir)
    output_dir_path = Path(output_dir)

    if not input_dir_path.exists():
        print(f"âŒ ì…ë ¥ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_dir_path}")
        return

    files = [f for f in input_dir_path.iterdir() if f.suffix == '.json']
    print(f"ğŸ“‚ ì´ {len(files)}ê°œì˜ íŒŒì¼ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì •ì œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\n")

    for file_path in files:
        new_filename = f"preprocessed_{file_path.name}"
        output_file_path = output_dir_path / new_filename
        process_json_file(file_path, output_file_path)

# ==========================================
# 3. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (Pathlib ì ìš©)
# ==========================================
def main() -> None:
    # __file__: í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì˜ ê²½ë¡œ
    # .resolve(): ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
    # .parents[2]: í˜„ì¬ ìœ„ì¹˜ì—ì„œ 2ë‹¨ê³„ ìƒìœ„ í´ë”(data)ë¥¼ base_dirë¡œ ì„¤ì •
    base_dir = Path(__file__).resolve().parents[2]

    # ì…ë ¥ ê²½ë¡œ ì°¾ê¸° (data/crawler/namuwiki/outputs/per-article)
    input_dir = base_dir / "crawler" / "namuwiki" / "outputs" / "per-article"

    # ì¶œë ¥ ê²½ë¡œ ì„¤ì • (data/preprocessed/namuwiki/outputs/per-article)
    output_dir = base_dir / "preprocessed" / "namuwiki" / "outputs" / "per-article"

    print(f"ğŸš€ ê¸°ì¤€ ê²½ë¡œ(Data): {base_dir}")
    print(f"ğŸ“‚ ì…ë ¥ ê²½ë¡œ: {input_dir}")
    print(f"ğŸ’¾ ì¶œë ¥ ê²½ë¡œ: {output_dir}")
    print("-" * 50)

    process_directory(input_dir, output_dir)
    print("âœ¨ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()